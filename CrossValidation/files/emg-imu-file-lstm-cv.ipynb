{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport numpy as np\nfrom pandas.io.json import json_normalize\n\nimport os\nimport glob as gb\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nimport keras \nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM , Flatten , CuDNNLSTM , GRU, Bidirectional\nfrom keras.layers import Dropout\nimport keras\n\nfrom keras import callbacks\nfrom keras.callbacks import  CSVLogger\n\n\n# Model Evaluations\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import KFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-26T20:46:16.967445Z","iopub.execute_input":"2022-10-26T20:46:16.968185Z","iopub.status.idle":"2022-10-26T20:46:27.664002Z","shell.execute_reply.started":"2022-10-26T20:46:16.968093Z","shell.execute_reply":"2022-10-26T20:46:27.662882Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def load_file(filepath,i):\n    with open(filepath) as f:\n        data = json.load(f)\n    imu = data['imu']['data']\n    emg = data['emg']['data']\n    emg = np.array(emg)\n    imu = np.array(imu)\n    imu_gyr = np.array([(e['gyroscope']) for e in imu])\n    imu_acc = np.array([(e['acceleration']) for e in imu])\n    imu_orn = np.array([(e['orientation']) for e in imu])\n    #timestamp = [i]\n    #timestamp = np.repeat(timestamp, 400, axis=None)\n    #timestamp= timestamp.reshape(400,1)\n    dataset = tf.concat([emg, imu_gyr, imu_acc, imu_orn], axis=1, name='concat')\n    dataset = np.array(dataset)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:46:27.669465Z","iopub.execute_input":"2022-10-26T20:46:27.673869Z","iopub.status.idle":"2022-10-26T20:46:27.687264Z","shell.execute_reply.started":"2022-10-26T20:46:27.673828Z","shell.execute_reply":"2022-10-26T20:46:27.686157Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/emgimu/An-EMG-and-IMU-Dataset-for-the-Italian-Sign-Language-Alphabet-master/Dataset/'","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:46:27.692256Z","iopub.execute_input":"2022-10-26T20:46:27.692645Z","iopub.status.idle":"2022-10-26T20:46:27.701594Z","shell.execute_reply.started":"2022-10-26T20:46:27.692598Z","shell.execute_reply":"2022-10-26T20:46:27.700584Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# For Files Data\nX = []\ny = []\ni=0\nfor folder in  os.listdir(data_path) : \n    j=0\n    files = gb.glob(pathname= str( data_path  + folder + '/*.json'))\n    for file in files: \n        data = load_file(file,j)\n        X.append(data)\n        y.append(i)\n        j+=1\n    i+=1\n\nprint(f'we have {len(X)} items in X ')","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:46:27.707300Z","iopub.execute_input":"2022-10-26T20:46:27.710044Z","iopub.status.idle":"2022-10-26T20:46:41.132769Z","shell.execute_reply.started":"2022-10-26T20:46:27.710010Z","shell.execute_reply":"2022-10-26T20:46:41.131754Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2022-10-26 20:46:27.885154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:27.886437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:28.230265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:28.231170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:28.232020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:28.232805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:28.236794: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-10-26 20:46:28.502609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:28.503524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:28.504391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:28.505167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:28.505989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:28.506757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:33.541286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:33.542250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:33.542983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:33.543719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:33.544456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:33.545127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-10-26 20:46:33.551459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:46:33.552174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"we have 780 items in X \n","output_type":"stream"}]},{"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:46:41.134419Z","iopub.execute_input":"2022-10-26T20:46:41.134792Z","iopub.status.idle":"2022-10-26T20:46:41.156312Z","shell.execute_reply.started":"2022-10-26T20:46:41.134755Z","shell.execute_reply":"2022-10-26T20:46:41.155372Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\nX, y = shuffle(X, y, random_state=20)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:46:41.157996Z","iopub.execute_input":"2022-10-26T20:46:41.158434Z","iopub.status.idle":"2022-10-26T20:46:41.182317Z","shell.execute_reply.started":"2022-10-26T20:46:41.158395Z","shell.execute_reply":"2022-10-26T20:46:41.181309Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print('X shape is : ' , X.shape)\nprint('y shape is : ' , y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:46:41.184036Z","iopub.execute_input":"2022-10-26T20:46:41.184437Z","iopub.status.idle":"2022-10-26T20:46:41.190661Z","shell.execute_reply.started":"2022-10-26T20:46:41.184402Z","shell.execute_reply":"2022-10-26T20:46:41.189223Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"X shape is :  (780, 400, 18)\ny shape is :  (780,)\n","output_type":"stream"}]},{"cell_type":"code","source":"mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, \n           'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, \n           'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:46:41.192594Z","iopub.execute_input":"2022-10-26T20:46:41.193091Z","iopub.status.idle":"2022-10-26T20:46:41.203894Z","shell.execute_reply.started":"2022-10-26T20:46:41.193054Z","shell.execute_reply":"2022-10-26T20:46:41.203042Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def getcode(n) : \n    for x , y in mapping.items() : \n        if n == y : \n            return x","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:46:41.205163Z","iopub.execute_input":"2022-10-26T20:46:41.206305Z","iopub.status.idle":"2022-10-26T20:46:41.215686Z","shell.execute_reply.started":"2022-10-26T20:46:41.206269Z","shell.execute_reply":"2022-10-26T20:46:41.214790Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X = X.reshape(len(X), X.shape[1],18)\ny = to_categorical(y)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:46:41.219222Z","iopub.execute_input":"2022-10-26T20:46:41.219674Z","iopub.status.idle":"2022-10-26T20:46:41.227083Z","shell.execute_reply.started":"2022-10-26T20:46:41.219638Z","shell.execute_reply":"2022-10-26T20:46:41.226060Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(X.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:46:41.228788Z","iopub.execute_input":"2022-10-26T20:46:41.229187Z","iopub.status.idle":"2022-10-26T20:46:41.236840Z","shell.execute_reply.started":"2022-10-26T20:46:41.229111Z","shell.execute_reply":"2022-10-26T20:46:41.235684Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"(780, 400, 18)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Building Model with files","metadata":{}},{"cell_type":"code","source":"kfold = KFold(n_splits=5, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:46:41.238643Z","iopub.execute_input":"2022-10-26T20:46:41.239143Z","iopub.status.idle":"2022-10-26T20:46:41.247218Z","shell.execute_reply.started":"2022-10-26T20:46:41.239107Z","shell.execute_reply":"2022-10-26T20:46:41.246131Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"acc_per_fold = []\nloss_per_fold = []\nfold_no = 1\nfor train, test in kfold.split(X, y):\n\n  # Model architecture\n    model = Sequential()\n    model.add(CuDNNLSTM(units=128, return_sequences=True, input_shape =(400,18)))\n    model.add(Dropout(0.3))\n    model.add(CuDNNLSTM(units=64, return_sequences=True))\n    model.add(Flatten())\n    model.add(Dense(26,activation='softmax'))\n\n\n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n#     es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n#     checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=\"./checkpoint-{epoch:02d}.hdf5\",\n#                                                       verbose=1, save_best_only=True,\n#                                                       monitor='val_acc',mode='max')\n#     csv_logger = CSVLogger('training_set_iranalysis3.csv',separator=',', append=False)\n\n\n\n\n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n\n    \n    history = model.fit(X[train], y[train], \n                        batch_size=128, epochs=40)\n\n    \n    scores = model.evaluate(X[test], y[test], verbose=0)\n    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; \\\n    {model.metrics_names[1]} of {scores[1]*100}%')\n    acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n\n    \n    fold_no = fold_no + 1","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:50:21.317441Z","iopub.execute_input":"2022-10-26T20:50:21.317830Z","iopub.status.idle":"2022-10-26T20:51:20.097127Z","shell.execute_reply.started":"2022-10-26T20:50:21.317797Z","shell.execute_reply":"2022-10-26T20:51:20.096002Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"------------------------------------------------------------------------\nTraining for fold 1 ...\nEpoch 1/40\n5/5 [==============================] - 2s 62ms/step - loss: 2.1409 - accuracy: 0.4151\nEpoch 2/40\n5/5 [==============================] - 0s 47ms/step - loss: 0.4662 - accuracy: 0.8670\nEpoch 3/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.1653 - accuracy: 0.9599\nEpoch 4/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.0633 - accuracy: 0.9824\nEpoch 5/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.0283 - accuracy: 0.9936\nEpoch 6/40\n5/5 [==============================] - 0s 47ms/step - loss: 0.0142 - accuracy: 0.9984\nEpoch 7/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0051 - accuracy: 1.0000\nEpoch 8/40\n5/5 [==============================] - 0s 46ms/step - loss: 0.0029 - accuracy: 1.0000\nEpoch 9/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0017 - accuracy: 1.0000\nEpoch 10/40\n5/5 [==============================] - 0s 48ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 11/40\n5/5 [==============================] - 0s 44ms/step - loss: 9.8522e-04 - accuracy: 1.0000\nEpoch 12/40\n5/5 [==============================] - 0s 44ms/step - loss: 7.3348e-04 - accuracy: 1.0000\nEpoch 13/40\n5/5 [==============================] - 0s 44ms/step - loss: 5.7559e-04 - accuracy: 1.0000\nEpoch 14/40\n5/5 [==============================] - 0s 80ms/step - loss: 4.9590e-04 - accuracy: 1.0000\nEpoch 15/40\n5/5 [==============================] - 0s 69ms/step - loss: 4.5594e-04 - accuracy: 1.0000\nEpoch 16/40\n5/5 [==============================] - 0s 67ms/step - loss: 4.0740e-04 - accuracy: 1.0000\nEpoch 17/40\n5/5 [==============================] - 0s 67ms/step - loss: 3.4765e-04 - accuracy: 1.0000\nEpoch 18/40\n5/5 [==============================] - 0s 61ms/step - loss: 3.5049e-04 - accuracy: 1.0000\nEpoch 19/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.2585e-04 - accuracy: 1.0000\nEpoch 20/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.0836e-04 - accuracy: 1.0000\nEpoch 21/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.9839e-04 - accuracy: 1.0000\nEpoch 22/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.9151e-04 - accuracy: 1.0000\nEpoch 23/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.7624e-04 - accuracy: 1.0000\nEpoch 24/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.4539e-04 - accuracy: 1.0000\nEpoch 25/40\n5/5 [==============================] - 0s 62ms/step - loss: 2.4378e-04 - accuracy: 1.0000\nEpoch 26/40\n5/5 [==============================] - 0s 64ms/step - loss: 2.2795e-04 - accuracy: 1.0000\nEpoch 27/40\n5/5 [==============================] - 0s 62ms/step - loss: 2.3464e-04 - accuracy: 1.0000\nEpoch 28/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.3378e-04 - accuracy: 1.0000\nEpoch 29/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.1244e-04 - accuracy: 1.0000\nEpoch 30/40\n5/5 [==============================] - 0s 43ms/step - loss: 2.1072e-04 - accuracy: 1.0000\nEpoch 31/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.1322e-04 - accuracy: 1.0000\nEpoch 32/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.0068e-04 - accuracy: 1.0000\nEpoch 33/40\n5/5 [==============================] - 0s 45ms/step - loss: 1.9154e-04 - accuracy: 1.0000\nEpoch 34/40\n5/5 [==============================] - 0s 45ms/step - loss: 1.8546e-04 - accuracy: 1.0000\nEpoch 35/40\n5/5 [==============================] - 0s 45ms/step - loss: 1.8391e-04 - accuracy: 1.0000\nEpoch 36/40\n5/5 [==============================] - 0s 45ms/step - loss: 1.7327e-04 - accuracy: 1.0000\nEpoch 37/40\n5/5 [==============================] - 0s 44ms/step - loss: 1.6920e-04 - accuracy: 1.0000\nEpoch 38/40\n5/5 [==============================] - 0s 44ms/step - loss: 1.6296e-04 - accuracy: 1.0000\nEpoch 39/40\n5/5 [==============================] - 0s 44ms/step - loss: 1.5130e-04 - accuracy: 1.0000\nEpoch 40/40\n5/5 [==============================] - 0s 44ms/step - loss: 1.5289e-04 - accuracy: 1.0000\nScore for fold 1: loss of 0.3626866638660431;     accuracy of 90.38461446762085%\n------------------------------------------------------------------------\nTraining for fold 2 ...\nEpoch 1/40\n5/5 [==============================] - 1s 61ms/step - loss: 2.2323 - accuracy: 0.3654\nEpoch 2/40\n5/5 [==============================] - 0s 55ms/step - loss: 0.4978 - accuracy: 0.8718\nEpoch 3/40\n5/5 [==============================] - 0s 46ms/step - loss: 0.1758 - accuracy: 0.9583\nEpoch 4/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0565 - accuracy: 0.9936\nEpoch 5/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0205 - accuracy: 0.9968\nEpoch 6/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0098 - accuracy: 1.0000\nEpoch 7/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0045 - accuracy: 1.0000\nEpoch 8/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.0027 - accuracy: 1.0000\nEpoch 9/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0015 - accuracy: 1.0000\nEpoch 10/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0013 - accuracy: 1.0000\nEpoch 11/40\n5/5 [==============================] - 0s 44ms/step - loss: 8.3422e-04 - accuracy: 1.0000\nEpoch 12/40\n5/5 [==============================] - 0s 45ms/step - loss: 6.5957e-04 - accuracy: 1.0000\nEpoch 13/40\n5/5 [==============================] - 0s 44ms/step - loss: 5.3996e-04 - accuracy: 1.0000\nEpoch 14/40\n5/5 [==============================] - 0s 44ms/step - loss: 5.1674e-04 - accuracy: 1.0000\nEpoch 15/40\n5/5 [==============================] - 0s 45ms/step - loss: 4.6892e-04 - accuracy: 1.0000\nEpoch 16/40\n5/5 [==============================] - 0s 45ms/step - loss: 4.6460e-04 - accuracy: 1.0000\nEpoch 17/40\n5/5 [==============================] - 0s 44ms/step - loss: 4.1810e-04 - accuracy: 1.0000\nEpoch 18/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.5809e-04 - accuracy: 1.0000\nEpoch 19/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.5988e-04 - accuracy: 1.0000\nEpoch 20/40\n5/5 [==============================] - 0s 45ms/step - loss: 3.2747e-04 - accuracy: 1.0000\nEpoch 21/40\n5/5 [==============================] - 0s 45ms/step - loss: 3.0660e-04 - accuracy: 1.0000\nEpoch 22/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.7669e-04 - accuracy: 1.0000\nEpoch 23/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.0323e-04 - accuracy: 1.0000\nEpoch 24/40\n5/5 [==============================] - 0s 58ms/step - loss: 2.7370e-04 - accuracy: 1.0000\nEpoch 25/40\n5/5 [==============================] - 0s 62ms/step - loss: 2.4852e-04 - accuracy: 1.0000\nEpoch 26/40\n5/5 [==============================] - 0s 62ms/step - loss: 2.3629e-04 - accuracy: 1.0000\nEpoch 27/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.3282e-04 - accuracy: 1.0000\nEpoch 28/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.1862e-04 - accuracy: 1.0000\nEpoch 29/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.2718e-04 - accuracy: 1.0000\nEpoch 30/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.2023e-04 - accuracy: 1.0000\nEpoch 31/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.0461e-04 - accuracy: 1.0000\nEpoch 32/40\n5/5 [==============================] - 0s 45ms/step - loss: 1.9335e-04 - accuracy: 1.0000\nEpoch 33/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.0236e-04 - accuracy: 1.0000\nEpoch 34/40\n5/5 [==============================] - 0s 45ms/step - loss: 1.8566e-04 - accuracy: 1.0000\nEpoch 35/40\n5/5 [==============================] - 0s 46ms/step - loss: 1.8557e-04 - accuracy: 1.0000\nEpoch 36/40\n5/5 [==============================] - 0s 45ms/step - loss: 1.7259e-04 - accuracy: 1.0000\nEpoch 37/40\n5/5 [==============================] - 0s 45ms/step - loss: 1.6443e-04 - accuracy: 1.0000\nEpoch 38/40\n5/5 [==============================] - 0s 44ms/step - loss: 1.7090e-04 - accuracy: 1.0000\nEpoch 39/40\n5/5 [==============================] - 0s 45ms/step - loss: 1.6011e-04 - accuracy: 1.0000\nEpoch 40/40\n5/5 [==============================] - 0s 44ms/step - loss: 1.6427e-04 - accuracy: 1.0000\nScore for fold 2: loss of 0.5132891535758972;     accuracy of 88.46153616905212%\n------------------------------------------------------------------------\nTraining for fold 3 ...\nEpoch 1/40\n5/5 [==============================] - 1s 51ms/step - loss: 2.2947 - accuracy: 0.3317\nEpoch 2/40\n5/5 [==============================] - 0s 46ms/step - loss: 0.5663 - accuracy: 0.8670\nEpoch 3/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.1789 - accuracy: 0.9535\nEpoch 4/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0630 - accuracy: 0.9904\nEpoch 5/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0244 - accuracy: 0.9952\nEpoch 6/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.0120 - accuracy: 0.9984\nEpoch 7/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.0035 - accuracy: 1.0000\nEpoch 8/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0025 - accuracy: 1.0000\nEpoch 9/40\n5/5 [==============================] - 0s 46ms/step - loss: 0.0017 - accuracy: 1.0000\nEpoch 10/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.0011 - accuracy: 1.0000\nEpoch 11/40\n5/5 [==============================] - 0s 44ms/step - loss: 9.1452e-04 - accuracy: 1.0000\nEpoch 12/40\n5/5 [==============================] - 0s 45ms/step - loss: 7.1692e-04 - accuracy: 1.0000\nEpoch 13/40\n5/5 [==============================] - 0s 44ms/step - loss: 6.4704e-04 - accuracy: 1.0000\nEpoch 14/40\n5/5 [==============================] - 0s 45ms/step - loss: 5.4130e-04 - accuracy: 1.0000\nEpoch 15/40\n5/5 [==============================] - 0s 45ms/step - loss: 4.5480e-04 - accuracy: 1.0000\nEpoch 16/40\n5/5 [==============================] - 0s 45ms/step - loss: 4.2663e-04 - accuracy: 1.0000\nEpoch 17/40\n5/5 [==============================] - 0s 44ms/step - loss: 4.0248e-04 - accuracy: 1.0000\nEpoch 18/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.7331e-04 - accuracy: 1.0000\nEpoch 19/40\n5/5 [==============================] - 0s 45ms/step - loss: 3.7095e-04 - accuracy: 1.0000\nEpoch 20/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.3705e-04 - accuracy: 1.0000\nEpoch 21/40\n5/5 [==============================] - 0s 45ms/step - loss: 3.2124e-04 - accuracy: 1.0000\nEpoch 22/40\n5/5 [==============================] - 0s 46ms/step - loss: 3.1038e-04 - accuracy: 1.0000\nEpoch 23/40\n5/5 [==============================] - 0s 63ms/step - loss: 3.1860e-04 - accuracy: 1.0000\nEpoch 24/40\n5/5 [==============================] - 0s 69ms/step - loss: 2.7116e-04 - accuracy: 1.0000\nEpoch 25/40\n5/5 [==============================] - 0s 61ms/step - loss: 2.7115e-04 - accuracy: 1.0000\nEpoch 26/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.6052e-04 - accuracy: 1.0000\nEpoch 27/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.6264e-04 - accuracy: 1.0000\nEpoch 28/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.4968e-04 - accuracy: 1.0000\nEpoch 29/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.3553e-04 - accuracy: 1.0000\nEpoch 30/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.3952e-04 - accuracy: 1.0000\nEpoch 31/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.3040e-04 - accuracy: 1.0000\nEpoch 32/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.0600e-04 - accuracy: 1.0000\nEpoch 33/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.0857e-04 - accuracy: 1.0000\nEpoch 34/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.1291e-04 - accuracy: 1.0000\nEpoch 35/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.0142e-04 - accuracy: 1.0000\nEpoch 36/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.0320e-04 - accuracy: 1.0000\nEpoch 37/40\n5/5 [==============================] - 0s 44ms/step - loss: 1.7596e-04 - accuracy: 1.0000\nEpoch 38/40\n5/5 [==============================] - 0s 45ms/step - loss: 1.7785e-04 - accuracy: 1.0000\nEpoch 39/40\n5/5 [==============================] - 0s 46ms/step - loss: 1.7536e-04 - accuracy: 1.0000\nEpoch 40/40\n5/5 [==============================] - 0s 44ms/step - loss: 1.7329e-04 - accuracy: 1.0000\nScore for fold 3: loss of 0.15884511172771454;     accuracy of 95.51281929016113%\n------------------------------------------------------------------------\nTraining for fold 4 ...\nEpoch 1/40\n5/5 [==============================] - 2s 78ms/step - loss: 2.2967 - accuracy: 0.3558\nEpoch 2/40\n5/5 [==============================] - 0s 67ms/step - loss: 0.5521 - accuracy: 0.8413\nEpoch 3/40\n5/5 [==============================] - 0s 70ms/step - loss: 0.2257 - accuracy: 0.9439\nEpoch 4/40\n5/5 [==============================] - 0s 73ms/step - loss: 0.0832 - accuracy: 0.9776\nEpoch 5/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.0263 - accuracy: 0.9968\nEpoch 6/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0146 - accuracy: 1.0000\nEpoch 7/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0057 - accuracy: 1.0000\nEpoch 8/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.0037 - accuracy: 1.0000\nEpoch 9/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.0024 - accuracy: 1.0000\nEpoch 10/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0017 - accuracy: 1.0000\nEpoch 11/40\n5/5 [==============================] - 0s 46ms/step - loss: 0.0013 - accuracy: 1.0000\nEpoch 12/40\n5/5 [==============================] - 0s 46ms/step - loss: 9.2369e-04 - accuracy: 1.0000\nEpoch 13/40\n5/5 [==============================] - 0s 47ms/step - loss: 7.4162e-04 - accuracy: 1.0000\nEpoch 14/40\n5/5 [==============================] - 0s 46ms/step - loss: 7.1525e-04 - accuracy: 1.0000\nEpoch 15/40\n5/5 [==============================] - 0s 45ms/step - loss: 6.3134e-04 - accuracy: 1.0000\nEpoch 16/40\n5/5 [==============================] - 0s 50ms/step - loss: 5.5895e-04 - accuracy: 1.0000\nEpoch 17/40\n5/5 [==============================] - 0s 72ms/step - loss: 5.4554e-04 - accuracy: 1.0000\nEpoch 18/40\n5/5 [==============================] - 0s 61ms/step - loss: 5.0586e-04 - accuracy: 1.0000\nEpoch 19/40\n5/5 [==============================] - 0s 47ms/step - loss: 4.6243e-04 - accuracy: 1.0000\nEpoch 20/40\n5/5 [==============================] - 0s 44ms/step - loss: 4.5574e-04 - accuracy: 1.0000\nEpoch 21/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.9299e-04 - accuracy: 1.0000\nEpoch 22/40\n5/5 [==============================] - 0s 45ms/step - loss: 3.7662e-04 - accuracy: 1.0000\nEpoch 23/40\n5/5 [==============================] - 0s 45ms/step - loss: 3.7891e-04 - accuracy: 1.0000\nEpoch 24/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.6209e-04 - accuracy: 1.0000\nEpoch 25/40\n5/5 [==============================] - 0s 43ms/step - loss: 3.2866e-04 - accuracy: 1.0000\nEpoch 26/40\n5/5 [==============================] - 0s 45ms/step - loss: 3.2577e-04 - accuracy: 1.0000\nEpoch 27/40\n5/5 [==============================] - 0s 46ms/step - loss: 3.3892e-04 - accuracy: 1.0000\nEpoch 28/40\n5/5 [==============================] - 0s 47ms/step - loss: 3.1680e-04 - accuracy: 1.0000\nEpoch 29/40\n5/5 [==============================] - 0s 51ms/step - loss: 3.1712e-04 - accuracy: 1.0000\nEpoch 30/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.9695e-04 - accuracy: 1.0000\nEpoch 31/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.9221e-04 - accuracy: 1.0000\nEpoch 32/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.8029e-04 - accuracy: 1.0000\nEpoch 33/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.6577e-04 - accuracy: 1.0000\nEpoch 34/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.5155e-04 - accuracy: 1.0000\nEpoch 35/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.5907e-04 - accuracy: 1.0000\nEpoch 36/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.4250e-04 - accuracy: 1.0000\nEpoch 37/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.2158e-04 - accuracy: 1.0000\nEpoch 38/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.2846e-04 - accuracy: 1.0000\nEpoch 39/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.1327e-04 - accuracy: 1.0000\nEpoch 40/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.0383e-04 - accuracy: 1.0000\nScore for fold 4: loss of 0.16320034861564636;     accuracy of 94.2307710647583%\n------------------------------------------------------------------------\nTraining for fold 5 ...\nEpoch 1/40\n5/5 [==============================] - 1s 60ms/step - loss: 2.3218 - accuracy: 0.3622\nEpoch 2/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.5892 - accuracy: 0.8429\nEpoch 3/40\n5/5 [==============================] - 0s 43ms/step - loss: 0.2047 - accuracy: 0.9599\nEpoch 4/40\n5/5 [==============================] - 0s 45ms/step - loss: 0.0646 - accuracy: 0.9904\nEpoch 5/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0207 - accuracy: 1.0000\nEpoch 6/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0090 - accuracy: 1.0000\nEpoch 7/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0043 - accuracy: 1.0000\nEpoch 8/40\n5/5 [==============================] - 0s 43ms/step - loss: 0.0025 - accuracy: 1.0000\nEpoch 9/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0020 - accuracy: 1.0000\nEpoch 10/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0014 - accuracy: 1.0000\nEpoch 11/40\n5/5 [==============================] - 0s 44ms/step - loss: 0.0011 - accuracy: 1.0000\nEpoch 12/40\n5/5 [==============================] - 0s 44ms/step - loss: 9.5148e-04 - accuracy: 1.0000\nEpoch 13/40\n5/5 [==============================] - 0s 45ms/step - loss: 7.6755e-04 - accuracy: 1.0000\nEpoch 14/40\n5/5 [==============================] - 0s 46ms/step - loss: 6.8823e-04 - accuracy: 1.0000\nEpoch 15/40\n5/5 [==============================] - 0s 73ms/step - loss: 5.9790e-04 - accuracy: 1.0000\nEpoch 16/40\n5/5 [==============================] - 0s 69ms/step - loss: 5.7411e-04 - accuracy: 1.0000\nEpoch 17/40\n5/5 [==============================] - 0s 62ms/step - loss: 4.9685e-04 - accuracy: 1.0000\nEpoch 18/40\n5/5 [==============================] - 0s 46ms/step - loss: 4.9269e-04 - accuracy: 1.0000\nEpoch 19/40\n5/5 [==============================] - 0s 44ms/step - loss: 4.6289e-04 - accuracy: 1.0000\nEpoch 20/40\n5/5 [==============================] - 0s 45ms/step - loss: 4.5581e-04 - accuracy: 1.0000\nEpoch 21/40\n5/5 [==============================] - 0s 44ms/step - loss: 4.4580e-04 - accuracy: 1.0000\nEpoch 22/40\n5/5 [==============================] - 0s 48ms/step - loss: 3.9941e-04 - accuracy: 1.0000\nEpoch 23/40\n5/5 [==============================] - 0s 47ms/step - loss: 3.7279e-04 - accuracy: 1.0000\nEpoch 24/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.8591e-04 - accuracy: 1.0000\nEpoch 25/40\n5/5 [==============================] - 0s 48ms/step - loss: 3.2785e-04 - accuracy: 1.0000\nEpoch 26/40\n5/5 [==============================] - 0s 47ms/step - loss: 3.3222e-04 - accuracy: 1.0000\nEpoch 27/40\n5/5 [==============================] - 0s 45ms/step - loss: 3.1763e-04 - accuracy: 1.0000\nEpoch 28/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.3082e-04 - accuracy: 1.0000\nEpoch 29/40\n5/5 [==============================] - 0s 44ms/step - loss: 3.0648e-04 - accuracy: 1.0000\nEpoch 30/40\n5/5 [==============================] - 0s 46ms/step - loss: 3.0659e-04 - accuracy: 1.0000\nEpoch 31/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.9240e-04 - accuracy: 1.0000\nEpoch 32/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.7951e-04 - accuracy: 1.0000\nEpoch 33/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.6792e-04 - accuracy: 1.0000\nEpoch 34/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.4016e-04 - accuracy: 1.0000\nEpoch 35/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.4901e-04 - accuracy: 1.0000\nEpoch 36/40\n5/5 [==============================] - 0s 48ms/step - loss: 2.2669e-04 - accuracy: 1.0000\nEpoch 37/40\n5/5 [==============================] - 0s 45ms/step - loss: 2.2739e-04 - accuracy: 1.0000\nEpoch 38/40\n5/5 [==============================] - 0s 46ms/step - loss: 2.3690e-04 - accuracy: 1.0000\nEpoch 39/40\n5/5 [==============================] - 0s 44ms/step - loss: 2.1864e-04 - accuracy: 1.0000\nEpoch 40/40\n5/5 [==============================] - 0s 46ms/step - loss: 1.9379e-04 - accuracy: 1.0000\nScore for fold 5: loss of 0.27499154210090637;     accuracy of 90.38461446762085%\n","output_type":"stream"}]},{"cell_type":"code","source":"print('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:51:20.100430Z","iopub.execute_input":"2022-10-26T20:51:20.100772Z","iopub.status.idle":"2022-10-26T20:51:20.109166Z","shell.execute_reply.started":"2022-10-26T20:51:20.100743Z","shell.execute_reply":"2022-10-26T20:51:20.107400Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"------------------------------------------------------------------------\nScore per fold\n------------------------------------------------------------------------\n> Fold 1 - Loss: 0.3626866638660431 - Accuracy: 90.38461446762085%\n------------------------------------------------------------------------\n> Fold 2 - Loss: 0.5132891535758972 - Accuracy: 88.46153616905212%\n------------------------------------------------------------------------\n> Fold 3 - Loss: 0.15884511172771454 - Accuracy: 95.51281929016113%\n------------------------------------------------------------------------\n> Fold 4 - Loss: 0.16320034861564636 - Accuracy: 94.2307710647583%\n------------------------------------------------------------------------\n> Fold 5 - Loss: 0.27499154210090637 - Accuracy: 90.38461446762085%\n------------------------------------------------------------------------\nAverage scores for all folds:\n> Accuracy: 91.79487109184265 (+- 2.6399059332956534)\n> Loss: 0.2946025639772415\n------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}