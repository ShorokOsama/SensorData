{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport numpy as np\nfrom pandas.io.json import json_normalize\n\nimport os\nimport glob as gb\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nimport keras \nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM , Flatten , CuDNNLSTM , GRU, Bidirectional\nfrom keras.layers import Dropout\nimport keras\n\nfrom keras import callbacks\nfrom keras.callbacks import  CSVLogger\n\n\n# Model Evaluations\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import KFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-26T20:28:43.211990Z","iopub.execute_input":"2022-10-26T20:28:43.213223Z","iopub.status.idle":"2022-10-26T20:28:49.553843Z","shell.execute_reply.started":"2022-10-26T20:28:43.213109Z","shell.execute_reply":"2022-10-26T20:28:49.552806Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def load_file(filepath,i):\n    with open(filepath) as f:\n        data = json.load(f)\n    imu = data['imu']['data']\n    emg = data['emg']['data']\n    emg = np.array(emg)\n    imu = np.array(imu)\n    imu_gyr = np.array([(e['gyroscope']) for e in imu])\n    imu_acc = np.array([(e['acceleration']) for e in imu])\n    imu_orn = np.array([(e['orientation']) for e in imu])\n    #timestamp = [i]\n    #timestamp = np.repeat(timestamp, 400, axis=None)\n    #timestamp= timestamp.reshape(400,1)\n    dataset = tf.concat([emg, imu_gyr, imu_acc, imu_orn], axis=1, name='concat')\n    dataset = np.array(dataset)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:28:49.556093Z","iopub.execute_input":"2022-10-26T20:28:49.557001Z","iopub.status.idle":"2022-10-26T20:28:49.565747Z","shell.execute_reply.started":"2022-10-26T20:28:49.556946Z","shell.execute_reply":"2022-10-26T20:28:49.563798Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/emgimu/An-EMG-and-IMU-Dataset-for-the-Italian-Sign-Language-Alphabet-master/Dataset/'","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:28:49.567803Z","iopub.execute_input":"2022-10-26T20:28:49.568281Z","iopub.status.idle":"2022-10-26T20:28:49.576729Z","shell.execute_reply.started":"2022-10-26T20:28:49.568241Z","shell.execute_reply":"2022-10-26T20:28:49.575791Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# For Files Data\nX = []\ny = []\ni=0\nfor folder in  os.listdir(data_path) : \n    j=0\n    files = gb.glob(pathname= str( data_path  + folder + '/*.json'))\n    for file in files: \n        data = load_file(file,j)\n        X.append(data)\n        y.append(i)\n        j+=1\n    i+=1\n\nprint(f'we have {len(X)} items in X ')","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:28:49.579918Z","iopub.execute_input":"2022-10-26T20:28:49.580351Z","iopub.status.idle":"2022-10-26T20:29:00.325207Z","shell.execute_reply.started":"2022-10-26T20:28:49.580315Z","shell.execute_reply":"2022-10-26T20:29:00.324276Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2022-10-26 20:28:49.725677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:49.726599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:49.893499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:49.894426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:49.895229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:49.896018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:49.899386: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-10-26 20:28:50.148370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:50.149281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:50.150156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:50.150911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:50.151655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:50.152431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:53.509154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:53.510111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:53.510900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:53.511709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:53.512426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:53.513088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-10-26 20:28:53.516998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-10-26 20:28:53.517759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"we have 780 items in X \n","output_type":"stream"}]},{"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:29:00.326564Z","iopub.execute_input":"2022-10-26T20:29:00.326976Z","iopub.status.idle":"2022-10-26T20:29:00.351307Z","shell.execute_reply.started":"2022-10-26T20:29:00.326935Z","shell.execute_reply":"2022-10-26T20:29:00.350094Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\nX, y = shuffle(X, y, random_state=20)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:29:00.352987Z","iopub.execute_input":"2022-10-26T20:29:00.353383Z","iopub.status.idle":"2022-10-26T20:29:00.376363Z","shell.execute_reply.started":"2022-10-26T20:29:00.353348Z","shell.execute_reply":"2022-10-26T20:29:00.375105Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print('X shape is : ' , X.shape)\nprint('y shape is : ' , y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:29:00.378144Z","iopub.execute_input":"2022-10-26T20:29:00.378514Z","iopub.status.idle":"2022-10-26T20:29:00.386602Z","shell.execute_reply.started":"2022-10-26T20:29:00.378479Z","shell.execute_reply":"2022-10-26T20:29:00.385386Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"X shape is :  (780, 400, 18)\ny shape is :  (780,)\n","output_type":"stream"}]},{"cell_type":"code","source":"mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, \n           'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, \n           'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:29:00.388151Z","iopub.execute_input":"2022-10-26T20:29:00.388430Z","iopub.status.idle":"2022-10-26T20:29:00.396450Z","shell.execute_reply.started":"2022-10-26T20:29:00.388405Z","shell.execute_reply":"2022-10-26T20:29:00.395272Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def getcode(n) : \n    for x , y in mapping.items() : \n        if n == y : \n            return x","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:29:00.398237Z","iopub.execute_input":"2022-10-26T20:29:00.398943Z","iopub.status.idle":"2022-10-26T20:29:00.405242Z","shell.execute_reply.started":"2022-10-26T20:29:00.398908Z","shell.execute_reply":"2022-10-26T20:29:00.404332Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X = X.reshape(len(X), X.shape[1],18)\ny = to_categorical(y)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:29:00.408875Z","iopub.execute_input":"2022-10-26T20:29:00.409210Z","iopub.status.idle":"2022-10-26T20:29:00.415797Z","shell.execute_reply.started":"2022-10-26T20:29:00.409168Z","shell.execute_reply":"2022-10-26T20:29:00.414933Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(X.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:29:00.419036Z","iopub.execute_input":"2022-10-26T20:29:00.419367Z","iopub.status.idle":"2022-10-26T20:29:00.426622Z","shell.execute_reply.started":"2022-10-26T20:29:00.419329Z","shell.execute_reply":"2022-10-26T20:29:00.425277Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"(780, 400, 18)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Building Model with files","metadata":{}},{"cell_type":"code","source":"kfold = KFold(n_splits=5, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:29:00.428228Z","iopub.execute_input":"2022-10-26T20:29:00.428690Z","iopub.status.idle":"2022-10-26T20:29:00.436940Z","shell.execute_reply.started":"2022-10-26T20:29:00.428657Z","shell.execute_reply":"2022-10-26T20:29:00.435456Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"acc_per_fold = []\nloss_per_fold = []\nfold_no = 1\nfor train, test in kfold.split(X, y):\n\n  # Model architecture\n    model = Sequential()\n    model.add(GRU(units=100, return_sequences=True, input_shape =(400,18), activation='tanh'))\n    model.add(Dropout(0.2))\n    model.add(GRU(units=50, return_sequences=True, activation='tanh'))\n    model.add(Dropout(0.2))\n    model.add(GRU(units=50, return_sequences=True, activation='tanh'))\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(26,activation='softmax'))\n\n\n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n#     es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n#     checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=\"./checkpoint-{epoch:02d}.hdf5\",\n#                                                       verbose=1, save_best_only=True,\n#                                                       monitor='val_acc',mode='max')\n#     csv_logger = CSVLogger('training_set_iranalysis3.csv',separator=',', append=False)\n\n\n\n\n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n\n    \n    history = model.fit(X[train], y[train], \n                        batch_size=128, epochs=40)\n\n    \n    scores = model.evaluate(X[test], y[test], verbose=0)\n    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; \\\n    {model.metrics_names[1]} of {scores[1]*100}%')\n    acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n\n    \n    fold_no = fold_no + 1","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:37:11.843868Z","iopub.execute_input":"2022-10-26T20:37:11.844389Z","iopub.status.idle":"2022-10-26T20:39:01.796858Z","shell.execute_reply.started":"2022-10-26T20:37:11.844346Z","shell.execute_reply":"2022-10-26T20:39:01.795808Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"------------------------------------------------------------------------\nTraining for fold 1 ...\nEpoch 1/40\n5/5 [==============================] - 4s 75ms/step - loss: 2.6790 - accuracy: 0.2772\nEpoch 2/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.7323 - accuracy: 0.8381\nEpoch 3/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.2636 - accuracy: 0.9551\nEpoch 4/40\n5/5 [==============================] - 0s 51ms/step - loss: 0.1141 - accuracy: 0.9776\nEpoch 5/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0419 - accuracy: 0.9968\nEpoch 6/40\n5/5 [==============================] - 0s 50ms/step - loss: 0.0196 - accuracy: 1.0000\nEpoch 7/40\n5/5 [==============================] - 0s 51ms/step - loss: 0.0092 - accuracy: 1.0000\nEpoch 8/40\n5/5 [==============================] - 0s 62ms/step - loss: 0.0051 - accuracy: 1.0000\nEpoch 9/40\n5/5 [==============================] - 0s 74ms/step - loss: 0.0035 - accuracy: 1.0000\nEpoch 10/40\n5/5 [==============================] - 0s 65ms/step - loss: 0.0027 - accuracy: 1.0000\nEpoch 11/40\n5/5 [==============================] - 0s 54ms/step - loss: 0.0021 - accuracy: 1.0000\nEpoch 12/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0019 - accuracy: 1.0000\nEpoch 13/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0015 - accuracy: 1.0000\nEpoch 14/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 15/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 16/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 17/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0011 - accuracy: 1.0000\nEpoch 18/40\n5/5 [==============================] - 0s 52ms/step - loss: 9.6602e-04 - accuracy: 1.0000\nEpoch 19/40\n5/5 [==============================] - 0s 52ms/step - loss: 9.4818e-04 - accuracy: 1.0000\nEpoch 20/40\n5/5 [==============================] - 0s 52ms/step - loss: 9.6442e-04 - accuracy: 1.0000\nEpoch 21/40\n5/5 [==============================] - 0s 53ms/step - loss: 8.5797e-04 - accuracy: 1.0000\nEpoch 22/40\n5/5 [==============================] - 0s 52ms/step - loss: 8.1100e-04 - accuracy: 1.0000\nEpoch 23/40\n5/5 [==============================] - 0s 52ms/step - loss: 7.3804e-04 - accuracy: 1.0000\nEpoch 24/40\n5/5 [==============================] - 0s 59ms/step - loss: 6.7762e-04 - accuracy: 1.0000\nEpoch 25/40\n5/5 [==============================] - 0s 52ms/step - loss: 7.3613e-04 - accuracy: 1.0000\nEpoch 26/40\n5/5 [==============================] - 0s 52ms/step - loss: 7.1322e-04 - accuracy: 1.0000\nEpoch 27/40\n5/5 [==============================] - 0s 52ms/step - loss: 6.7125e-04 - accuracy: 1.0000\nEpoch 28/40\n5/5 [==============================] - 0s 52ms/step - loss: 6.3512e-04 - accuracy: 1.0000\nEpoch 29/40\n5/5 [==============================] - 0s 52ms/step - loss: 6.8382e-04 - accuracy: 1.0000\nEpoch 30/40\n5/5 [==============================] - 0s 52ms/step - loss: 5.9274e-04 - accuracy: 1.0000\nEpoch 31/40\n5/5 [==============================] - 0s 52ms/step - loss: 5.9557e-04 - accuracy: 1.0000\nEpoch 32/40\n5/5 [==============================] - 0s 52ms/step - loss: 5.7130e-04 - accuracy: 1.0000\nEpoch 33/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.2449e-04 - accuracy: 1.0000\nEpoch 34/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.1057e-04 - accuracy: 1.0000\nEpoch 35/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.1515e-04 - accuracy: 1.0000\nEpoch 36/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.3147e-04 - accuracy: 1.0000\nEpoch 37/40\n5/5 [==============================] - 0s 52ms/step - loss: 5.1319e-04 - accuracy: 1.0000\nEpoch 38/40\n5/5 [==============================] - 0s 51ms/step - loss: 4.6507e-04 - accuracy: 1.0000\nEpoch 39/40\n5/5 [==============================] - 0s 53ms/step - loss: 4.5046e-04 - accuracy: 1.0000\nEpoch 40/40\n5/5 [==============================] - 0s 52ms/step - loss: 4.5479e-04 - accuracy: 1.0000\nScore for fold 1: loss of 0.3923863172531128;     accuracy of 89.10256624221802%\n------------------------------------------------------------------------\nTraining for fold 2 ...\nEpoch 1/40\n5/5 [==============================] - 4s 76ms/step - loss: 2.3028 - accuracy: 0.3558\nEpoch 2/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.5852 - accuracy: 0.8766\nEpoch 3/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.2201 - accuracy: 0.9487\nEpoch 4/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0860 - accuracy: 0.9904\nEpoch 5/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0347 - accuracy: 0.9968\nEpoch 6/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0121 - accuracy: 1.0000\nEpoch 7/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0070 - accuracy: 1.0000\nEpoch 8/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0046 - accuracy: 1.0000\nEpoch 9/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0029 - accuracy: 1.0000\nEpoch 10/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0022 - accuracy: 1.0000\nEpoch 11/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0016 - accuracy: 1.0000\nEpoch 12/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0016 - accuracy: 1.0000\nEpoch 13/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0013 - accuracy: 1.0000\nEpoch 14/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 15/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0011 - accuracy: 1.0000\nEpoch 16/40\n5/5 [==============================] - 0s 54ms/step - loss: 9.7812e-04 - accuracy: 1.0000\nEpoch 17/40\n5/5 [==============================] - 0s 53ms/step - loss: 9.2762e-04 - accuracy: 1.0000\nEpoch 18/40\n5/5 [==============================] - 0s 52ms/step - loss: 8.6326e-04 - accuracy: 1.0000\nEpoch 19/40\n5/5 [==============================] - 0s 53ms/step - loss: 8.1341e-04 - accuracy: 1.0000\nEpoch 20/40\n5/5 [==============================] - 0s 54ms/step - loss: 7.9404e-04 - accuracy: 1.0000\nEpoch 21/40\n5/5 [==============================] - 0s 53ms/step - loss: 8.0230e-04 - accuracy: 1.0000\nEpoch 22/40\n5/5 [==============================] - 0s 55ms/step - loss: 7.0369e-04 - accuracy: 1.0000\nEpoch 23/40\n5/5 [==============================] - 0s 53ms/step - loss: 6.9392e-04 - accuracy: 1.0000\nEpoch 24/40\n5/5 [==============================] - 0s 52ms/step - loss: 6.1340e-04 - accuracy: 1.0000\nEpoch 25/40\n5/5 [==============================] - 0s 54ms/step - loss: 6.1168e-04 - accuracy: 1.0000\nEpoch 26/40\n5/5 [==============================] - 0s 55ms/step - loss: 5.7699e-04 - accuracy: 1.0000\nEpoch 27/40\n5/5 [==============================] - 0s 53ms/step - loss: 6.2276e-04 - accuracy: 1.0000\nEpoch 28/40\n5/5 [==============================] - 0s 54ms/step - loss: 5.2782e-04 - accuracy: 1.0000\nEpoch 29/40\n5/5 [==============================] - 0s 55ms/step - loss: 5.2564e-04 - accuracy: 1.0000\nEpoch 30/40\n5/5 [==============================] - 0s 54ms/step - loss: 5.2630e-04 - accuracy: 1.0000\nEpoch 31/40\n5/5 [==============================] - 0s 55ms/step - loss: 4.8245e-04 - accuracy: 1.0000\nEpoch 32/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.0891e-04 - accuracy: 1.0000\nEpoch 33/40\n5/5 [==============================] - 0s 54ms/step - loss: 4.9152e-04 - accuracy: 1.0000\nEpoch 34/40\n5/5 [==============================] - 0s 53ms/step - loss: 4.7836e-04 - accuracy: 1.0000\nEpoch 35/40\n5/5 [==============================] - 0s 54ms/step - loss: 4.5406e-04 - accuracy: 1.0000\nEpoch 36/40\n5/5 [==============================] - 0s 53ms/step - loss: 4.2062e-04 - accuracy: 1.0000\nEpoch 37/40\n5/5 [==============================] - 0s 87ms/step - loss: 4.2672e-04 - accuracy: 1.0000\nEpoch 38/40\n5/5 [==============================] - 0s 71ms/step - loss: 4.0835e-04 - accuracy: 1.0000\nEpoch 39/40\n5/5 [==============================] - 0s 52ms/step - loss: 3.9310e-04 - accuracy: 1.0000\nEpoch 40/40\n5/5 [==============================] - 0s 53ms/step - loss: 3.9899e-04 - accuracy: 1.0000\nScore for fold 2: loss of 0.40911272168159485;     accuracy of 91.02563858032227%\n------------------------------------------------------------------------\nTraining for fold 3 ...\nEpoch 1/40\n5/5 [==============================] - 4s 92ms/step - loss: 2.4713 - accuracy: 0.3141\nEpoch 2/40\n5/5 [==============================] - 0s 81ms/step - loss: 0.6499 - accuracy: 0.8462\nEpoch 3/40\n5/5 [==============================] - 0s 87ms/step - loss: 0.2495 - accuracy: 0.9423\nEpoch 4/40\n5/5 [==============================] - 0s 77ms/step - loss: 0.1193 - accuracy: 0.9760\nEpoch 5/40\n5/5 [==============================] - 0s 60ms/step - loss: 0.0348 - accuracy: 0.9968\nEpoch 6/40\n5/5 [==============================] - 0s 54ms/step - loss: 0.0213 - accuracy: 1.0000\nEpoch 7/40\n5/5 [==============================] - 0s 54ms/step - loss: 0.0081 - accuracy: 1.0000\nEpoch 8/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0053 - accuracy: 1.0000\nEpoch 9/40\n5/5 [==============================] - 0s 54ms/step - loss: 0.0036 - accuracy: 1.0000\nEpoch 10/40\n5/5 [==============================] - 0s 55ms/step - loss: 0.0024 - accuracy: 1.0000\nEpoch 11/40\n5/5 [==============================] - 0s 55ms/step - loss: 0.0017 - accuracy: 1.0000\nEpoch 12/40\n5/5 [==============================] - 0s 54ms/step - loss: 0.0016 - accuracy: 1.0000\nEpoch 13/40\n5/5 [==============================] - 0s 54ms/step - loss: 0.0013 - accuracy: 1.0000\nEpoch 14/40\n5/5 [==============================] - 0s 90ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 15/40\n5/5 [==============================] - 0s 76ms/step - loss: 0.0011 - accuracy: 1.0000\nEpoch 16/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0010 - accuracy: 1.0000\nEpoch 17/40\n5/5 [==============================] - 0s 52ms/step - loss: 9.0461e-04 - accuracy: 1.0000\nEpoch 18/40\n5/5 [==============================] - 0s 53ms/step - loss: 9.4726e-04 - accuracy: 1.0000\nEpoch 19/40\n5/5 [==============================] - 0s 53ms/step - loss: 8.7547e-04 - accuracy: 1.0000\nEpoch 20/40\n5/5 [==============================] - 0s 53ms/step - loss: 8.6309e-04 - accuracy: 1.0000\nEpoch 21/40\n5/5 [==============================] - 0s 53ms/step - loss: 9.0940e-04 - accuracy: 1.0000\nEpoch 22/40\n5/5 [==============================] - 0s 53ms/step - loss: 7.5817e-04 - accuracy: 1.0000\nEpoch 23/40\n5/5 [==============================] - 0s 53ms/step - loss: 7.1587e-04 - accuracy: 1.0000\nEpoch 24/40\n5/5 [==============================] - 0s 53ms/step - loss: 7.3363e-04 - accuracy: 1.0000\nEpoch 25/40\n5/5 [==============================] - 0s 54ms/step - loss: 7.4922e-04 - accuracy: 1.0000\nEpoch 26/40\n5/5 [==============================] - 0s 52ms/step - loss: 6.4863e-04 - accuracy: 1.0000\nEpoch 27/40\n5/5 [==============================] - 0s 54ms/step - loss: 6.2298e-04 - accuracy: 1.0000\nEpoch 28/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.8803e-04 - accuracy: 1.0000\nEpoch 29/40\n5/5 [==============================] - 0s 52ms/step - loss: 6.5643e-04 - accuracy: 1.0000\nEpoch 30/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.5660e-04 - accuracy: 1.0000\nEpoch 31/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.7167e-04 - accuracy: 1.0000\nEpoch 32/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.4332e-04 - accuracy: 1.0000\nEpoch 33/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.1799e-04 - accuracy: 1.0000\nEpoch 34/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.1015e-04 - accuracy: 1.0000\nEpoch 35/40\n5/5 [==============================] - 0s 52ms/step - loss: 5.0416e-04 - accuracy: 1.0000\nEpoch 36/40\n5/5 [==============================] - 0s 52ms/step - loss: 4.8255e-04 - accuracy: 1.0000\nEpoch 37/40\n5/5 [==============================] - 0s 53ms/step - loss: 4.7268e-04 - accuracy: 1.0000\nEpoch 38/40\n5/5 [==============================] - 0s 54ms/step - loss: 4.4215e-04 - accuracy: 1.0000\nEpoch 39/40\n5/5 [==============================] - 0s 53ms/step - loss: 4.2708e-04 - accuracy: 1.0000\nEpoch 40/40\n5/5 [==============================] - 0s 52ms/step - loss: 4.4140e-04 - accuracy: 1.0000\nScore for fold 3: loss of 0.6351039409637451;     accuracy of 88.46153616905212%\n------------------------------------------------------------------------\nTraining for fold 4 ...\nEpoch 1/40\n5/5 [==============================] - 4s 78ms/step - loss: 2.6054 - accuracy: 0.2917\nEpoch 2/40\n5/5 [==============================] - 0s 54ms/step - loss: 0.7496 - accuracy: 0.8494\nEpoch 3/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.2429 - accuracy: 0.9535\nEpoch 4/40\n5/5 [==============================] - 0s 75ms/step - loss: 0.0988 - accuracy: 0.9824\nEpoch 5/40\n5/5 [==============================] - 0s 74ms/step - loss: 0.0292 - accuracy: 0.9968\nEpoch 6/40\n5/5 [==============================] - 0s 64ms/step - loss: 0.0131 - accuracy: 1.0000\nEpoch 7/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0076 - accuracy: 1.0000\nEpoch 8/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0044 - accuracy: 1.0000\nEpoch 9/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0026 - accuracy: 1.0000\nEpoch 10/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0021 - accuracy: 1.0000\nEpoch 11/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0017 - accuracy: 1.0000\nEpoch 12/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0014 - accuracy: 1.0000\nEpoch 13/40\n5/5 [==============================] - 0s 55ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 14/40\n5/5 [==============================] - 0s 55ms/step - loss: 0.0010 - accuracy: 1.0000\nEpoch 15/40\n5/5 [==============================] - 0s 53ms/step - loss: 8.9201e-04 - accuracy: 1.0000\nEpoch 16/40\n5/5 [==============================] - 0s 52ms/step - loss: 8.8899e-04 - accuracy: 1.0000\nEpoch 17/40\n5/5 [==============================] - 0s 53ms/step - loss: 8.2402e-04 - accuracy: 1.0000\nEpoch 18/40\n5/5 [==============================] - 0s 55ms/step - loss: 8.2537e-04 - accuracy: 1.0000\nEpoch 19/40\n5/5 [==============================] - 0s 53ms/step - loss: 7.6412e-04 - accuracy: 1.0000\nEpoch 20/40\n5/5 [==============================] - 0s 54ms/step - loss: 7.3963e-04 - accuracy: 1.0000\nEpoch 21/40\n5/5 [==============================] - 0s 55ms/step - loss: 6.5131e-04 - accuracy: 1.0000\nEpoch 22/40\n5/5 [==============================] - 0s 53ms/step - loss: 6.3431e-04 - accuracy: 1.0000\nEpoch 23/40\n5/5 [==============================] - 0s 55ms/step - loss: 6.4683e-04 - accuracy: 1.0000\nEpoch 24/40\n5/5 [==============================] - 0s 81ms/step - loss: 6.4280e-04 - accuracy: 1.0000\nEpoch 25/40\n5/5 [==============================] - 0s 81ms/step - loss: 6.1801e-04 - accuracy: 1.0000\nEpoch 26/40\n5/5 [==============================] - 0s 80ms/step - loss: 6.1206e-04 - accuracy: 1.0000\nEpoch 27/40\n5/5 [==============================] - 0s 79ms/step - loss: 5.8262e-04 - accuracy: 1.0000\nEpoch 28/40\n5/5 [==============================] - 0s 56ms/step - loss: 5.4732e-04 - accuracy: 1.0000\nEpoch 29/40\n5/5 [==============================] - 0s 52ms/step - loss: 5.4787e-04 - accuracy: 1.0000\nEpoch 30/40\n5/5 [==============================] - 0s 55ms/step - loss: 5.4474e-04 - accuracy: 1.0000\nEpoch 31/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.3978e-04 - accuracy: 1.0000\nEpoch 32/40\n5/5 [==============================] - 0s 52ms/step - loss: 4.9054e-04 - accuracy: 1.0000\nEpoch 33/40\n5/5 [==============================] - 0s 52ms/step - loss: 4.6402e-04 - accuracy: 1.0000\nEpoch 34/40\n5/5 [==============================] - 0s 53ms/step - loss: 4.5346e-04 - accuracy: 1.0000\nEpoch 35/40\n5/5 [==============================] - 0s 52ms/step - loss: 4.3793e-04 - accuracy: 1.0000\nEpoch 36/40\n5/5 [==============================] - 0s 52ms/step - loss: 4.4190e-04 - accuracy: 1.0000\nEpoch 37/40\n5/5 [==============================] - 0s 55ms/step - loss: 4.0015e-04 - accuracy: 1.0000\nEpoch 38/40\n5/5 [==============================] - 0s 54ms/step - loss: 4.0377e-04 - accuracy: 1.0000\nEpoch 39/40\n5/5 [==============================] - 0s 53ms/step - loss: 3.6481e-04 - accuracy: 1.0000\nEpoch 40/40\n5/5 [==============================] - 0s 51ms/step - loss: 3.5656e-04 - accuracy: 1.0000\nScore for fold 4: loss of 0.2905692458152771;     accuracy of 89.74359035491943%\n------------------------------------------------------------------------\nTraining for fold 5 ...\nEpoch 1/40\n5/5 [==============================] - 4s 75ms/step - loss: 2.7623 - accuracy: 0.2420\nEpoch 2/40\n5/5 [==============================] - 0s 54ms/step - loss: 0.9251 - accuracy: 0.7644\nEpoch 3/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.3051 - accuracy: 0.9551\nEpoch 4/40\n5/5 [==============================] - 0s 55ms/step - loss: 0.1280 - accuracy: 0.9728\nEpoch 5/40\n5/5 [==============================] - 0s 54ms/step - loss: 0.0444 - accuracy: 0.9952\nEpoch 6/40\n5/5 [==============================] - 0s 55ms/step - loss: 0.0204 - accuracy: 1.0000\nEpoch 7/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0102 - accuracy: 1.0000\nEpoch 8/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0054 - accuracy: 1.0000\nEpoch 9/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0044 - accuracy: 1.0000\nEpoch 10/40\n5/5 [==============================] - 0s 51ms/step - loss: 0.0031 - accuracy: 1.0000\nEpoch 11/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0026 - accuracy: 1.0000\nEpoch 12/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0022 - accuracy: 1.0000\nEpoch 13/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0019 - accuracy: 1.0000\nEpoch 14/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0018 - accuracy: 1.0000\nEpoch 15/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0014 - accuracy: 1.0000\nEpoch 16/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0015 - accuracy: 1.0000\nEpoch 17/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 18/40\n5/5 [==============================] - 0s 53ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 19/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0013 - accuracy: 1.0000\nEpoch 20/40\n5/5 [==============================] - 0s 51ms/step - loss: 0.0011 - accuracy: 1.0000\nEpoch 21/40\n5/5 [==============================] - 0s 52ms/step - loss: 0.0011 - accuracy: 1.0000\nEpoch 22/40\n5/5 [==============================] - 0s 76ms/step - loss: 0.0010 - accuracy: 1.0000\nEpoch 23/40\n5/5 [==============================] - 0s 70ms/step - loss: 9.7450e-04 - accuracy: 1.0000\nEpoch 24/40\n5/5 [==============================] - 0s 64ms/step - loss: 9.8051e-04 - accuracy: 1.0000\nEpoch 25/40\n5/5 [==============================] - 0s 58ms/step - loss: 9.6717e-04 - accuracy: 1.0000\nEpoch 26/40\n5/5 [==============================] - 0s 53ms/step - loss: 8.9479e-04 - accuracy: 1.0000\nEpoch 27/40\n5/5 [==============================] - 0s 54ms/step - loss: 8.1027e-04 - accuracy: 1.0000\nEpoch 28/40\n5/5 [==============================] - 0s 52ms/step - loss: 8.1724e-04 - accuracy: 1.0000\nEpoch 29/40\n5/5 [==============================] - 0s 52ms/step - loss: 8.0124e-04 - accuracy: 1.0000\nEpoch 30/40\n5/5 [==============================] - 0s 51ms/step - loss: 7.4285e-04 - accuracy: 1.0000\nEpoch 31/40\n5/5 [==============================] - 0s 53ms/step - loss: 7.4256e-04 - accuracy: 1.0000\nEpoch 32/40\n5/5 [==============================] - 0s 52ms/step - loss: 7.1418e-04 - accuracy: 1.0000\nEpoch 33/40\n5/5 [==============================] - 0s 52ms/step - loss: 6.3311e-04 - accuracy: 1.0000\nEpoch 34/40\n5/5 [==============================] - 0s 53ms/step - loss: 6.6740e-04 - accuracy: 1.0000\nEpoch 35/40\n5/5 [==============================] - 0s 52ms/step - loss: 6.1687e-04 - accuracy: 1.0000\nEpoch 36/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.8336e-04 - accuracy: 1.0000\nEpoch 37/40\n5/5 [==============================] - 0s 52ms/step - loss: 5.7663e-04 - accuracy: 1.0000\nEpoch 38/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.7785e-04 - accuracy: 1.0000\nEpoch 39/40\n5/5 [==============================] - 0s 54ms/step - loss: 5.6432e-04 - accuracy: 1.0000\nEpoch 40/40\n5/5 [==============================] - 0s 53ms/step - loss: 5.2501e-04 - accuracy: 1.0000\nScore for fold 5: loss of 0.17266005277633667;     accuracy of 96.79487347602844%\n","output_type":"stream"}]},{"cell_type":"code","source":"print('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","metadata":{"execution":{"iopub.status.busy":"2022-10-26T20:39:01.801746Z","iopub.execute_input":"2022-10-26T20:39:01.802525Z","iopub.status.idle":"2022-10-26T20:39:01.816599Z","shell.execute_reply.started":"2022-10-26T20:39:01.802483Z","shell.execute_reply":"2022-10-26T20:39:01.815215Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"------------------------------------------------------------------------\nScore per fold\n------------------------------------------------------------------------\n> Fold 1 - Loss: 0.3923863172531128 - Accuracy: 89.10256624221802%\n------------------------------------------------------------------------\n> Fold 2 - Loss: 0.40911272168159485 - Accuracy: 91.02563858032227%\n------------------------------------------------------------------------\n> Fold 3 - Loss: 0.6351039409637451 - Accuracy: 88.46153616905212%\n------------------------------------------------------------------------\n> Fold 4 - Loss: 0.2905692458152771 - Accuracy: 89.74359035491943%\n------------------------------------------------------------------------\n> Fold 5 - Loss: 0.17266005277633667 - Accuracy: 96.79487347602844%\n------------------------------------------------------------------------\nAverage scores for all folds:\n> Accuracy: 91.02564096450806 (+- 3.0066774794489377)\n> Loss: 0.3799664556980133\n------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}